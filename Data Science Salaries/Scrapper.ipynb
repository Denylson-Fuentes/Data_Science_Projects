{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe4ab90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e0d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44159a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def versionOne(job_listings, jobs_data, verion):\n",
    "    # Print the job titles\n",
    "    for job_listing in job_listings:\n",
    "        \n",
    "        # Gathering Rating name data\n",
    "        try:\n",
    "            rating = job_listing.find_element(By.XPATH, './/div[@class=\"job-title mt-xsm\"]')\n",
    "            rating = rating.text\n",
    "        except Exception as e:\n",
    "#             print(\"No title was found: \")\n",
    "            rating = '-'\n",
    "            pass\n",
    "        print(rating)\n",
    "        # Gathering Title name data\n",
    "        try:\n",
    "            title = job_listing.find_element(By.XPATH, './/div[@class=\"job-title mt-xsm\"]')\n",
    "            title = title.text\n",
    "        except Exception as e:\n",
    "#             print(\"No title was found: \")\n",
    "            title = \"Data Scientist\"\n",
    "            pass\n",
    "    \n",
    "        # Gathering Company name data\n",
    "        try:\n",
    "            company = job_listing.find_element(By.XPATH, './/div[@class=\"job-search-8wag7x\"]')\n",
    "            company = company.text\n",
    "        except Exception as e:\n",
    "#             print(\"No Company was found: \")\n",
    "            company = '-'\n",
    "            pass\n",
    "        \n",
    "        # Gathering Location name data \n",
    "        try:\n",
    "            location = job_listing.find_element(By.XPATH, './/div[@class=\"location mt-xxsm\"]')\n",
    "            location = location.text\n",
    "        except Exception as e:\n",
    "#             print(\"No location was found: \")\n",
    "            location = '-'\n",
    "            pass\n",
    "    \n",
    "        # Gathering Salary name data\n",
    "        try:\n",
    "            salary = job_listing.find_element(By.XPATH, './/div[@class=\"salary-estimate\"]')\n",
    "            salary = salary.text\n",
    "        except Exception as e:\n",
    "#             print(\"No salary was found: \")\n",
    "            salary = '-'\n",
    "            pass\n",
    "# Gathering Job Description data\n",
    "        try:\n",
    "            jd = job_listing.find_element(By.XPATH, './/div[@class=\"jobDescriptionContent desc\"]')\n",
    "            jd = salary.text\n",
    "        except Exception as e:\n",
    "            print(\"No Job description was  found: \")\n",
    "            jd = '-'\n",
    "            pass\n",
    "            \n",
    "        print(jd)\n",
    "#         print(title, company, rating, location, salary, jd)\n",
    "        jobs_data.append({'Title': title, 'Rating': rating, 'Company': company, 'Location': location, 'Salary': salary})\n",
    "    return jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02a2dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def versionTwo(job_listings, jobs_data, version):\n",
    "    # Print the job titles\n",
    "    for job_listing in job_listings:\n",
    "        \n",
    "        # Gathering Rating name data\n",
    "        try:\n",
    "            rating = job_listing.find_element(By.XPATH, './/span[@data-test=\"detailRating\"]')\n",
    "            rating = rating.text\n",
    "        except Exception as e:\n",
    "#             print(\"No title was found: \")\n",
    "            rating = '-'\n",
    "            pass\n",
    "        \n",
    "        # Gathering Title name data\n",
    "        try:\n",
    "            title = job_listing.find_element(By.XPATH, './/div[@data-test=\"jobTitle\"]')\n",
    "            title = title.text\n",
    "        except Exception as e:\n",
    "#             print(\"No title was found: \")\n",
    "            title = \"Data Scientist\"\n",
    "            pass\n",
    "        \n",
    "        # Gathering Company name data\n",
    "        try:\n",
    "            company = job_listing.find_element(By.XPATH, './/div[@class=\"employerName\"]')\n",
    "            company = company.text\n",
    "        except Exception as e:\n",
    "#             print(\"No Company was found: \")\n",
    "            company = '-'\n",
    "            pass\n",
    "    \n",
    "        # Gathering Location name data    \n",
    "        try:\n",
    "            location = job_listing.find_element(By.XPATH, './/div[@data-test=\"location\"]')\n",
    "            location = location.text\n",
    "        except Exception as e:\n",
    "#             print(\"No location was found: \")\n",
    "            location = '-'\n",
    "            pass\n",
    "        \n",
    "        # Gathering Salary  data\n",
    "        try:\n",
    "            salary = job_listing.find_element(By.XPATH, './/div[@class=\"detailSalary\"]')\n",
    "            salary = salary.text\n",
    "        except Exception as e:\n",
    "#             print(\"No Salary was  found: \")\n",
    "            salary = '-'\n",
    "            pass\n",
    "    \n",
    "    # Gathering Job Description data\n",
    "        try:\n",
    "            jd = job_listing.find_element(By.XPATH, './/div[@class=\"jobDescriptionContent desc\"]')\n",
    "            jd = salary.text\n",
    "        except Exception as e:\n",
    "#             print(\"No Salary was  found: \")\n",
    "            jd = '-'\n",
    "            pass\n",
    "            \n",
    "            \n",
    "#         print(title, company, rating, location, salary, jd)\n",
    "        jobs_data.append({'Title': title, 'Rating': rating, 'Company': company, 'Location': location, 'Salary': salary})\n",
    "    return jobs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e850e5b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(job, job_location):\n",
    "    print('Looking for {} positions in {}'.format(job, job_location))\n",
    "    # Set up the WebDriver\n",
    "    #Initializing the webdriver\n",
    "    options = webdriver.ChromeOptions()\n",
    "\n",
    "    #Uncomment the line below if you'd like to scrape without a new Chrome window every time.\n",
    "    #options.add_argument('headless')\n",
    "\n",
    "    #Change the path to where chromedriver is in your home folder.\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(1120, 1000) # Replace 'path_to_chrome_driver' with the actual path to your Chrome WebDriver executable\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    # Navigate to the Glassdoor website\n",
    "    driver.get(\"https://www.glassdoor.com/Job/jobs.htm?suggestCount=0&suggestChosen=false&clickSource=searchBtn&typedKeyword=\"+job+\"&sc.keyword=\"+job+\"&locT=&locId=&jobType=\")\n",
    "\n",
    "    # # Locate and click the \"Jobs\" link\n",
    "    # jobs_link = wait.until(EC.presence_of_element_located((By.XPATH, '//b[@class=\"lockedHomeHeader__LockedHomeHeaderStyles__mainMenuItem\"]')))\n",
    "    # jobs_link.click()\n",
    "    \n",
    "    # Make driver wait for everything to load\n",
    "    driver.implicitly_wait(25)\n",
    "    \n",
    "    # Locate and fill in the job search keyword\n",
    "#     search_box = wait.until(EC.presence_of_element_located((By.XPATH, '//input[@data-test=\"search-bar-keyword-input\"]')))\n",
    "#     search_box.send_keys(job)  # Replace 'software engineer' with your desired job search keyword\n",
    "\n",
    "    # Locate and fill in the job search location\n",
    "    try:\n",
    "        location_box = wait.until(EC.presence_of_element_located((By.XPATH, '//input[@data-test=\"search-bar-location-input\"]')))\n",
    "        location_box.clear()\n",
    "        location_box.send_keys(job_location)  # Replace 'San Francisco' with your desired job search location\n",
    "\n",
    "        # Submit the job search form\n",
    "        search_button = wait.until(EC.presence_of_element_located((By.XPATH, '//button[@data-test=\"search-bar-submit\"]')))\n",
    "        search_button.click()\n",
    "    except Exception as e:\n",
    "        return -1\n",
    "\n",
    "#     #Click on the \"See All Jobs\" link\n",
    "#     jobs_button = wait.until(EC.presence_of_element_located((By.XPATH, '//strong[@class=\"mr-xxsm\"]')))\n",
    "#     jobs_button.click()\n",
    "#     # Wait for the job search results to load\n",
    "#     driver.implicitly_wait(10)\n",
    "\n",
    "    #Fetching the amount of pages the result has\n",
    "#     pages = driver.find_element(By.XPATH, './/div[@data-test=\"pagination-footer-text\"]')\n",
    "# #     pages = pages.text.split()\n",
    "#     print(pages.text)\n",
    "\n",
    "    #Extracting more than one page of job results\n",
    "    pages = [2 + n for n in range(0, 10)]\n",
    "    jobs_data = []\n",
    "    for page in pages:\n",
    "        print('-' * 50)\n",
    "        print('On page {}'.format(page-1))\n",
    "        \n",
    "        # Checking if there is a mini window to close to close and continue data mining\n",
    "        try:\n",
    "            mini_window_button = wait.until(EC.element_to_be_clickable((By.XPATH, './/button[@class=\"e1jbctw80 ei0fd8p1 css-1n14mz9 e1q8sty40\"]')))\n",
    "            mini_window_button.click()\n",
    "        except Exception as e:\n",
    "    #         print(\"No mini window\")\n",
    "            pass\n",
    "\n",
    "        # Extract the job listings\n",
    "        job_listings = driver.find_elements(By.XPATH, '//li[contains(@class, \"react-job-listing css-108gl9c eigr9kq3\")]')\n",
    "\n",
    "        if page == 2:\n",
    "            jobs_data = versionOne(job_listings, jobs_data, 1)\n",
    "        else:\n",
    "            jobs_data = versionTwo(job_listings, jobs_data, 2)\n",
    "\n",
    "\n",
    "\n",
    "        try:\n",
    "            path = '//button[@data-test=\"pagination-link-%s\"]'%page\n",
    "            page_button = WebDriverWait(driver, 50).until(EC.element_to_be_clickable((By.XPATH, path)))\n",
    "            page_button.click()\n",
    "            print('-' * 50)\n",
    "        except Exception as e:\n",
    "            break\n",
    "        \n",
    "    #Close the WebDriver\n",
    "    driver.quit()\n",
    "    \n",
    "    df = pd.DataFrame(jobs_data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6cfba5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for data scientist positions in Alabama\n",
      "Looking for data scientist positions in Alaska\n",
      "--------------------------------------------------\n",
      "On page 1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "versionOne() missing 1 required positional argument: 'verion'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m state \u001b[38;5;129;01min\u001b[39;00m state_names:\n\u001b[1;32m---> 13\u001b[0m     state_df \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata scientist\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state_df \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m: \n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[17], line 70\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(job, job_location)\u001b[0m\n\u001b[0;32m     67\u001b[0m job_listings \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m//li[contains(@class, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreact-job-listing css-108gl9c eigr9kq3\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m page \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     jobs_data \u001b[38;5;241m=\u001b[39m \u001b[43mversionOne\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_listings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjobs_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     jobs_data \u001b[38;5;241m=\u001b[39m versionTwo(job_listings, jobs_data)\n",
      "\u001b[1;31mTypeError\u001b[0m: versionOne() missing 1 required positional argument: 'verion'"
     ]
    }
   ],
   "source": [
    "state_names=[\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\",\n",
    "             \"Colorado\", \"Connecticut\", \"Delaware\", \"Florida\", \"Georgia\",\n",
    "             \"Hawaii\", \"Idaho\", \"Illinois\", \"Indiana\", \"Iowa\",\n",
    "             \"Kansas\", \"Kentucky\", \"Louisiana\", \"Maine\", \"Maryland\",\n",
    "             \"Massachusetts\", \"Michigan\", \"Minnesota\", \"Mississippi\", \"Missouri\",\n",
    "             \"Montana\", \"Nebraska\", \"Nevada\", \"New Hampshire\", \"New Jersey\",\n",
    "             \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\", \"Ohio\",\n",
    "             \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Rhode Island\", \"South Carolina\",\n",
    "             \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Vermont\",\n",
    "             \"Virginia\", \"Washington\", \"West Virginia\", \"Wisconsin\", \"Wyoming\"]\n",
    "df = pd.DataFrame()\n",
    "for state in state_names:\n",
    "    state_df = get_data('data scientist', state)\n",
    "    \n",
    "    if state_df == -1: \n",
    "        continue\n",
    "        \n",
    "    datasets = [df, state_df]\n",
    "    df = pd.concat(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb35fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97f8ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a13ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./salaries.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afec7b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salaries",
   "language": "python",
   "name": "salaries"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
